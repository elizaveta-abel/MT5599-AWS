{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab604d62-b7ea-4340-affc-312c678affca",
   "metadata": {},
   "source": [
    "Uploading raw datasets to S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5046670-960d-484d-ab23-6abce2e888ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [14:01<00:00,  3.33s/it]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import tqdm\n",
    "\n",
    "for i in tqdm.tqdm(range(0, 253)):\n",
    "    obj = \"spanish_tweets_2016_\" + str(i) + \".json\"\n",
    "    obj_loc = \"../../data/\" + obj\n",
    "    boto3.Session().resource('s3').Bucket(\"mt5599\").Object(\"tweets/\" + obj).upload_file(obj_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd403041-2bd0-4ae9-8bbc-a99197c2abc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on  s3://mt5599/tweets/spanish_tweets_2016_1.json\n",
      "reading in data\n",
      "removing unnecessary columns\n",
      "filtering out tweets that have no location data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/347793 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  0%|          | 33/347793 [00:00<36:27, 158.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 99590/347793 [11:42<33:42, 122.71it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|██████████| 347793/347793 [1:07:33<00:00, 85.80it/s]\n",
      "  0%|          | 0/347793 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  0%|          | 86/347793 [00:00<13:44, 421.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347793/347793 [20:16<00:00, 285.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "done\n",
      "347793\n",
      "working on  s3://mt5599/tweets/spanish_tweets_2016_2.json\n",
      "reading in data\n",
      "removing unnecessary columns\n",
      "filtering out tweets that have no location data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/346203 [00:00<35:14, 163.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 346203/346203 [1:06:18<00:00, 87.02it/s]\n",
      "  0%|          | 86/346203 [00:00<13:35, 424.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 346203/346203 [19:43<00:00, 292.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "done\n",
      "693996\n",
      "working on  s3://mt5599/tweets/spanish_tweets_2016_3.json\n",
      "reading in data\n",
      "removing unnecessary columns\n",
      "filtering out tweets that have no location data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/395551 [00:00<45:38, 144.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395551/395551 [1:27:56<00:00, 74.96it/s]\n",
      "  0%|          | 74/395551 [00:00<18:04, 364.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395551/395551 [27:22<00:00, 240.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "done\n",
      "1089547\n",
      "working on  s3://mt5599/tweets/spanish_tweets_2016_4.json\n",
      "reading in data\n",
      "removing unnecessary columns\n",
      "filtering out tweets that have no location data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/307450 [00:00<29:00, 176.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307450/307450 [52:25<00:00, 97.76it/s] \n",
      "  0%|          | 96/307450 [00:00<10:51, 471.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307450/307450 [15:27<00:00, 331.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "done\n",
      "1396997\n",
      "working on  s3://mt5599/tweets/spanish_tweets_2016_5.json\n",
      "reading in data\n",
      "removing unnecessary columns\n",
      "filtering out tweets that have no location data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 43/265931 [00:00<21:07, 209.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265931/265931 [38:44<00:00, 114.40it/s]\n",
      "  0%|          | 110/265931 [00:00<08:10, 542.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265931/265931 [10:48<00:00, 410.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "done\n",
      "1662928\n",
      "working on  s3://mt5599/tweets/spanish_tweets_2016_6.json\n",
      "reading in data\n",
      "removing unnecessary columns\n",
      "filtering out tweets that have no location data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/289829 [00:00<24:56, 193.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting components of place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 123343/289829 [13:00<23:21, 118.83it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import tqdm\n",
    "from multiprocessing import Pool # multithreading\n",
    "import gc\n",
    "\n",
    "# write function to remove unnecessary columns\n",
    "def keep_columns(df, # dataframe to be cleaned\n",
    "                 columns): # list of columns to keep\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "#write function to keep only tweets with location data\n",
    "def has_loc(df):\n",
    "    df = df[df.coordinates != \"None\"]\n",
    "    df = df[df.place != \"None\"]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# helper function to extract place and coordinates\n",
    "def safe_json_loads(string):\n",
    "    try:\n",
    "        string = json.loads(string)\n",
    "    except:\n",
    "        string = None\n",
    "    return(string)\n",
    "\n",
    "\n",
    "# extracting place components\n",
    "def extract_place(df):\n",
    "    \n",
    "    df_coord = df\n",
    "    \n",
    "    df_coord['place_full_name'] = \"None\"\n",
    "    df_coord['place_name'] = \"None\"\n",
    "    df_coord['place_type'] = \"None\"\n",
    "    df_coord['place_country'] = \"None\"\n",
    "    df_coord['place_country_code'] = \"None\"\n",
    "\n",
    "    for i in tqdm.tqdm(range(df_coord.shape[0])):\n",
    "\n",
    "        if df_coord.place[i] != \"None\":\n",
    "            try:\n",
    "                split_by = \"Place\\(fullName='|', name='|', type='|', country='|', countryCode='|'\\)\"\n",
    "                temp = re.split(split_by, df_coord.place[i])\n",
    "\n",
    "                df_coord['place_full_name'][i] = temp[1]\n",
    "                df_coord['place_name'][i] = temp[2]\n",
    "                df_coord['place_type'][i] = temp[3]\n",
    "                df_coord['place_country'][i] = temp[4]\n",
    "                df_coord['place_country_code'][i] = temp[5]\n",
    "            except:\n",
    "                df_coord['place_full_name'][i] = None\n",
    "                df_coord['place_name'][i] = None\n",
    "                df_coord['place_type'][i] = None\n",
    "                df_coord['place_country'][i] = None\n",
    "                df_coord['place_country_code'][i] = None\n",
    "                \n",
    "    return df_coord\n",
    "\n",
    "\n",
    "# extracting coordinates components\n",
    "def extract_coordinates(df):\n",
    "    \n",
    "    df_coord = df\n",
    "    \n",
    "    df_coord['coordinates_longitude'] = \"None\"\n",
    "    df_coord['coordinates_latitude'] = \"None\"\n",
    "\n",
    "    for i in tqdm.tqdm(range(df_coord.shape[0])):\n",
    "\n",
    "        if df_coord.coordinates[i] != \"None\":\n",
    "            try:\n",
    "                split_by = \"Coordinates\\(longitude=|, latitude=|\\)\"\n",
    "                temp = re.split(split_by, df_coord.coordinates[i])\n",
    "\n",
    "                df_coord['coordinates_longitude'][i] = temp[1]\n",
    "                df_coord['coordinates_latitude'][i] = temp[2]\n",
    "\n",
    "            except:\n",
    "                df_coord['coordinates_longitude'][i] = None\n",
    "                df_coord['coordinates_latitude'][i] = None\n",
    "                \n",
    "    return df_coord\n",
    "\n",
    "\n",
    "\n",
    "def clean_df(filepath):\n",
    "    \n",
    "    print(\"working on \", filepath)\n",
    "    \n",
    "    print(\"reading in data\")\n",
    "    df = pd.read_json(filepath)\n",
    "\n",
    "    print(\"removing unnecessary columns\")\n",
    "    df = keep_columns(df, [\"id\", \"DateTime\", \"coordinates\", \"place\", \"username\", \"user_location\"])\n",
    "\n",
    "    print(\"filtering out tweets that have no location data\")\n",
    "    df = has_loc(df)\n",
    "\n",
    "    print(\"extracting components of place\")\n",
    "    df = extract_place(df)\n",
    "\n",
    "    print(\"extracting components of coordinates\")\n",
    "    df = extract_coordinates(df)\n",
    "    \n",
    "    print(\"saving\")\n",
    "    df.to_feather(\"s3://mt5599/tweets/spanish_tweets_2016_processed\" + str(i) + \".feather\")\n",
    "\n",
    "    num = df.shape[0]\n",
    "    \n",
    "    print(\"done\")\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    return num\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    filepaths = []\n",
    "    for i in range(1, 253):\n",
    "        filepath = \"s3://mt5599/tweets/spanish_tweets_2016_\" + str(i) + \".json\"\n",
    "        filepaths.append(filepath)\n",
    "    \n",
    "    total_tweets = 0\n",
    "    for filepath in filepaths:\n",
    "        tweet_no = clean_df(filepath)\n",
    "        total_tweets = total_tweets + tweet_no\n",
    "        print(total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7702224f-454b-4889-b823-0f2e40b7e9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing unnecessary columns\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-872af72c9587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"removing unnecessary columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DateTime\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coordinates\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"place\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"username\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user_location\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keeping only tweets with location data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "filepath = \"s3://mt5599/tweets/spanish_tweets_2016_\" + str(0) + \".json\"\n",
    "\n",
    "#print(\"starting to process \", filepath)\n",
    "#df = pd.read_json(filepath)\n",
    "\n",
    "print(\"removing unnecessary columns\")\n",
    "df = keep_columns(df, [\"id\", \"DateTime\", \"coordinates\", \"place\", \"username\", \"user_location\"])\n",
    "\n",
    "print(\"keeping only tweets with location data\")\n",
    "df = has_loc(df)\n",
    "\n",
    "print(\"extracting components of place\")\n",
    "df = extract_place(df)\n",
    "\n",
    "print(\"extracting components of coodinates\")\n",
    "df = extract_coordinates(df)\n",
    "\n",
    "df.to_feather(\"s3://mt5599/tweets/spanish_tweets_2016_processed_\" + str(0) + \".feather\")\n",
    "\n",
    "print(\"done\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5b4008-0f06-41ef-ba92-e67d0184ec25",
   "metadata": {},
   "source": [
    "Reading in datasets and combining them. Saving them as feather file in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b38561-86ef-447c-9571-2f367fec342e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish_tweets_2016_0  done\n",
      "spanish_tweets_2016_1  done\n",
      "spanish_tweets_2016_2  done\n",
      "spanish_tweets_2016_3  done\n",
      "spanish_tweets_2016_4  done\n",
      "spanish_tweets_2016_5  done\n",
      "spanish_tweets_2016_6  done\n",
      "spanish_tweets_2016_7  done\n",
      "spanish_tweets_2016_8  done\n",
      "spanish_tweets_2016_9  done\n",
      "spanish_tweets_2016_10  done\n",
      "spanish_tweets_2016_11  done\n",
      "spanish_tweets_2016_12  done\n",
      "spanish_tweets_2016_13  done\n",
      "spanish_tweets_2016_14  done\n",
      "spanish_tweets_2016_15  done\n",
      "spanish_tweets_2016_16  done\n",
      "spanish_tweets_2016_17  done\n",
      "spanish_tweets_2016_18  done\n",
      "spanish_tweets_2016_19  done\n",
      "spanish_tweets_2016_20  done\n",
      "spanish_tweets_2016_21  done\n",
      "spanish_tweets_2016_22  done\n",
      "spanish_tweets_2016_23  done\n",
      "spanish_tweets_2016_24  done\n",
      "spanish_tweets_2016_25  done\n",
      "spanish_tweets_2016_26  done\n",
      "spanish_tweets_2016_27  done\n",
      "spanish_tweets_2016_28  done\n",
      "spanish_tweets_2016_29  done\n",
      "spanish_tweets_2016_30  done\n",
      "spanish_tweets_2016_31  done\n",
      "spanish_tweets_2016_32  done\n",
      "spanish_tweets_2016_33  done\n",
      "spanish_tweets_2016_34  done\n",
      "spanish_tweets_2016_35  done\n",
      "spanish_tweets_2016_36  done\n",
      "spanish_tweets_2016_37  done\n",
      "spanish_tweets_2016_38  done\n",
      "spanish_tweets_2016_39  done\n",
      "spanish_tweets_2016_40  done\n",
      "spanish_tweets_2016_41  done\n",
      "spanish_tweets_2016_42  done\n",
      "spanish_tweets_2016_43  done\n",
      "spanish_tweets_2016_44  done\n",
      "spanish_tweets_2016_45  done\n",
      "spanish_tweets_2016_46  done\n",
      "spanish_tweets_2016_47  done\n",
      "spanish_tweets_2016_48  done\n",
      "spanish_tweets_2016_49  done\n",
      "spanish_tweets_2016_50  done\n",
      "spanish_tweets_2016_51  done\n",
      "spanish_tweets_2016_52  done\n",
      "spanish_tweets_2016_53  done\n",
      "spanish_tweets_2016_54  done\n",
      "spanish_tweets_2016_55  done\n",
      "spanish_tweets_2016_56  done\n",
      "spanish_tweets_2016_57  done\n",
      "spanish_tweets_2016_58  done\n",
      "spanish_tweets_2016_59  done\n",
      "spanish_tweets_2016_60  done\n",
      "spanish_tweets_2016_61  done\n",
      "spanish_tweets_2016_62  done\n",
      "spanish_tweets_2016_63  done\n",
      "spanish_tweets_2016_64  done\n",
      "spanish_tweets_2016_65  done\n",
      "spanish_tweets_2016_66  done\n",
      "spanish_tweets_2016_67  done\n",
      "spanish_tweets_2016_68  done\n",
      "spanish_tweets_2016_69  done\n",
      "spanish_tweets_2016_70  done\n",
      "spanish_tweets_2016_71  done\n",
      "spanish_tweets_2016_72  done\n",
      "spanish_tweets_2016_73  done\n",
      "spanish_tweets_2016_74  done\n",
      "spanish_tweets_2016_75  done\n",
      "spanish_tweets_2016_76  done\n",
      "spanish_tweets_2016_77  done\n",
      "spanish_tweets_2016_78  done\n",
      "spanish_tweets_2016_79  done\n",
      "spanish_tweets_2016_80  done\n",
      "spanish_tweets_2016_81  done\n",
      "spanish_tweets_2016_82  done\n",
      "spanish_tweets_2016_83  done\n",
      "spanish_tweets_2016_84  done\n",
      "spanish_tweets_2016_85  done\n",
      "spanish_tweets_2016_86  done\n",
      "spanish_tweets_2016_87  done\n",
      "spanish_tweets_2016_88  done\n",
      "spanish_tweets_2016_89  done\n",
      "spanish_tweets_2016_90  done\n",
      "spanish_tweets_2016_91  done\n",
      "spanish_tweets_2016_92  done\n",
      "spanish_tweets_2016_93  done\n",
      "spanish_tweets_2016_94  done\n",
      "spanish_tweets_2016_95  done\n",
      "spanish_tweets_2016_96  done\n",
      "spanish_tweets_2016_97  done\n",
      "spanish_tweets_2016_98  done\n",
      "spanish_tweets_2016_99  done\n",
      "spanish_tweets_2016_100  done\n",
      "spanish_tweets_2016_101  done\n",
      "spanish_tweets_2016_102  done\n",
      "spanish_tweets_2016_103  done\n",
      "spanish_tweets_2016_104  done\n",
      "spanish_tweets_2016_105  done\n",
      "spanish_tweets_2016_106  done\n",
      "spanish_tweets_2016_107  done\n",
      "spanish_tweets_2016_108  done\n",
      "spanish_tweets_2016_109  done\n",
      "spanish_tweets_2016_110  done\n",
      "spanish_tweets_2016_111  done\n",
      "spanish_tweets_2016_112  done\n",
      "spanish_tweets_2016_113  done\n",
      "spanish_tweets_2016_114  done\n",
      "spanish_tweets_2016_115  done\n",
      "spanish_tweets_2016_116  done\n",
      "spanish_tweets_2016_117  done\n",
      "spanish_tweets_2016_118  done\n",
      "spanish_tweets_2016_119  done\n",
      "spanish_tweets_2016_120  done\n",
      "spanish_tweets_2016_121  done\n",
      "spanish_tweets_2016_122  done\n",
      "spanish_tweets_2016_123  done\n",
      "spanish_tweets_2016_124  done\n",
      "spanish_tweets_2016_125  done\n",
      "spanish_tweets_2016_126  done\n",
      "spanish_tweets_2016_127  done\n",
      "spanish_tweets_2016_128  done\n",
      "spanish_tweets_2016_129  done\n",
      "spanish_tweets_2016_130  done\n",
      "spanish_tweets_2016_131  done\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "files = []\n",
    "DataFrameName = []\n",
    "for i in range(0, 253):\n",
    "    files.append(\"s3://mt5599/tweets/spanish_tweets_2016_\" + str(i) + \".json\")\n",
    "    DataFrameName.append(\"spanish_tweets_2016_\" + str(i))\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for name, file in zip(DataFrameName, files):\n",
    "    dfs[name] = pd.read_json(file)\n",
    "    print(name, \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb231e0-c299-4bf6-9ed9-a15f69400055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs.values(), ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9dc048-9f49-43e5-bbea-c96ce799e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "\n",
    "df.to_feather(\"../../data/df_2016.feather\")\n",
    "boto3.Session().resource('s3').Bucket(\"mt5599\").Object(\"tweets/df_2016.feather\").upload_file(\"../../data/df_2016.feather\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.12xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:712779665605:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
