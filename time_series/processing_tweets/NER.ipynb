{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db52f3c7-8592-447e-b71a-c05935b298a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\n",
      "Collecting feather-format\n",
      "  Using cached feather_format-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyarrow>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from feather-format) (11.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.13.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: feather-format\n",
      "Successfully installed feather-format-0.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers feather-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b867f2f-2985-4dba-abe6-6787149e8d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbab7451-8764-4544-b584-78274d4e824e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForTokenClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-57c531257c3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Davlan/bert-base-multilingual-cased-ner-hrl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForTokenClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Davlan/bert-base-multilingual-cased-ner-hrl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ner\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"simple\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#group_sub_entities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"_from_config\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nAutoModelForTokenClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import boto3\n",
    "import os\n",
    "from time import process_time\n",
    "import io\n",
    "import tqdm\n",
    "import feather\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from multiprocessing import Pool # multithreading\n",
    "from time import process_time\n",
    "import unicodedata\n",
    "import html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Davlan/bert-base-multilingual-cased-ner-hrl\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Davlan/bert-base-multilingual-cased-ner-hrl\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\") #group_sub_entities\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4daf901-3fdd-454d-826a-83c9bc931ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68ca6c-41ec-4d88-a21a-07ad78ca76cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0b2b9-eda9-4b1d-aec9-0f469b9e5381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c20e3a-22e8-46a4-b3c4-2037a662ca51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e6f84-7699-4aaf-9f15-0a15fe0dff22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452467cc-4448-4b21-b0e6-8560ed74ca79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>username</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_country</th>\n",
       "      <th>place_country_code</th>\n",
       "      <th>coordinates_longitude</th>\n",
       "      <th>coordinates_latitude</th>\n",
       "      <th>ner_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>722512957247242240</td>\n",
       "      <td>2016-04-19 19:51:27+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>darcena2553</td>\n",
       "      <td>2358639522</td>\n",
       "      <td>No soy unica soy diferente</td>\n",
       "      <td>https://t.co/CGRUcZWccL</td>\n",
       "      <td>zxx</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>718879627956068352</td>\n",
       "      <td>2016-04-09 19:13:54+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>darcena2553</td>\n",
       "      <td>2358639522</td>\n",
       "      <td>No soy unica soy diferente</td>\n",
       "      <td>Que chiste más malo pero me rio igual</td>\n",
       "      <td>es</td>\n",
       "      <td>Que chiste ms malo pero me rio igual</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>718879522431639552</td>\n",
       "      <td>2016-04-09 19:13:28+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>darcena2553</td>\n",
       "      <td>2358639522</td>\n",
       "      <td>No soy unica soy diferente</td>\n",
       "      <td>Habia perro llamado pegento, se callo y se pego</td>\n",
       "      <td>es</td>\n",
       "      <td>Habia perro llamado pegento, se callo y se pego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>718878528020852736</td>\n",
       "      <td>2016-04-09 19:09:31+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>darcena2553</td>\n",
       "      <td>2358639522</td>\n",
       "      <td>No soy unica soy diferente</td>\n",
       "      <td>Siento que cada día que pasa es un día menos p...</td>\n",
       "      <td>es</td>\n",
       "      <td>Siento que cada da que pasa es un da menos par...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>718240922379644928</td>\n",
       "      <td>2016-04-08 00:55:54+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>darcena2553</td>\n",
       "      <td>2358639522</td>\n",
       "      <td>No soy unica soy diferente</td>\n",
       "      <td>La zorra dr mierda va un paso adelante y yo un...</td>\n",
       "      <td>es</td>\n",
       "      <td>La zorra dr mierda va un paso adelante y yo un...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897594</th>\n",
       "      <td>20143</td>\n",
       "      <td>649401814627041280</td>\n",
       "      <td>2015-10-01 01:53:52+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ss_gladys</td>\n",
       "      <td>527972155</td>\n",
       "      <td>planeta tierra🌎</td>\n",
       "      <td>@rociolupe1 @AngelesMayer @Camac_Rejas @patric...</td>\n",
       "      <td>it</td>\n",
       "      <td>bello grupo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897595</th>\n",
       "      <td>20144</td>\n",
       "      <td>649378989933490176</td>\n",
       "      <td>2015-10-01 00:23:10+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ss_gladys</td>\n",
       "      <td>527972155</td>\n",
       "      <td>planeta tierra🌎</td>\n",
       "      <td>@nan_diosa @SusanaBeatrzDaz @sebahaesler1 @spl...</td>\n",
       "      <td>es</td>\n",
       "      <td>linda noche besotes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897596</th>\n",
       "      <td>20145</td>\n",
       "      <td>649378714539716608</td>\n",
       "      <td>2015-10-01 00:22:05+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ss_gladys</td>\n",
       "      <td>527972155</td>\n",
       "      <td>planeta tierra🌎</td>\n",
       "      <td>@AngelesMayer @Camac_Rejas @patricia170919 @LM...</td>\n",
       "      <td>es</td>\n",
       "      <td>buenas noches amigos besitos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897597</th>\n",
       "      <td>20146</td>\n",
       "      <td>649378118281625600</td>\n",
       "      <td>2015-10-01 00:19:42+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ss_gladys</td>\n",
       "      <td>527972155</td>\n",
       "      <td>planeta tierra🌎</td>\n",
       "      <td>@jacquelin_93 @ThEcualizere @kitty_sanrio1 @Si...</td>\n",
       "      <td>es</td>\n",
       "      <td>feliz noche corazones besos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897598</th>\n",
       "      <td>20147</td>\n",
       "      <td>649374394276573184</td>\n",
       "      <td>2015-10-01 00:04:55+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ss_gladys</td>\n",
       "      <td>527972155</td>\n",
       "      <td>planeta tierra🌎</td>\n",
       "      <td>#GHLaGranFinal #matiasal3002 ,palpitando la gr...</td>\n",
       "      <td>es</td>\n",
       "      <td>GHLaGranFinal matiasal3002 ,palpitando la gra...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>897599 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                  id                  DateTime coordinates place  \\\n",
       "0           0  722512957247242240 2016-04-19 19:51:27+00:00        None  None   \n",
       "1           1  718879627956068352 2016-04-09 19:13:54+00:00        None  None   \n",
       "2           2  718879522431639552 2016-04-09 19:13:28+00:00        None  None   \n",
       "3           3  718878528020852736 2016-04-09 19:09:31+00:00        None  None   \n",
       "4           4  718240922379644928 2016-04-08 00:55:54+00:00        None  None   \n",
       "...       ...                 ...                       ...         ...   ...   \n",
       "897594  20143  649401814627041280 2015-10-01 01:53:52+00:00        None  None   \n",
       "897595  20144  649378989933490176 2015-10-01 00:23:10+00:00        None  None   \n",
       "897596  20145  649378714539716608 2015-10-01 00:22:05+00:00        None  None   \n",
       "897597  20146  649378118281625600 2015-10-01 00:19:42+00:00        None  None   \n",
       "897598  20147  649374394276573184 2015-10-01 00:04:55+00:00        None  None   \n",
       "\n",
       "           username     user_id               user_location  \\\n",
       "0       darcena2553  2358639522  No soy unica soy diferente   \n",
       "1       darcena2553  2358639522  No soy unica soy diferente   \n",
       "2       darcena2553  2358639522  No soy unica soy diferente   \n",
       "3       darcena2553  2358639522  No soy unica soy diferente   \n",
       "4       darcena2553  2358639522  No soy unica soy diferente   \n",
       "...             ...         ...                         ...   \n",
       "897594    ss_gladys   527972155            planeta tierra🌎    \n",
       "897595    ss_gladys   527972155            planeta tierra🌎    \n",
       "897596    ss_gladys   527972155            planeta tierra🌎    \n",
       "897597    ss_gladys   527972155            planeta tierra🌎    \n",
       "897598    ss_gladys   527972155            planeta tierra🌎    \n",
       "\n",
       "                                            tweet_content lang  \\\n",
       "0                                 https://t.co/CGRUcZWccL  zxx   \n",
       "1                   Que chiste más malo pero me rio igual   es   \n",
       "2         Habia perro llamado pegento, se callo y se pego   es   \n",
       "3       Siento que cada día que pasa es un día menos p...   es   \n",
       "4       La zorra dr mierda va un paso adelante y yo un...   es   \n",
       "...                                                   ...  ...   \n",
       "897594  @rociolupe1 @AngelesMayer @Camac_Rejas @patric...   it   \n",
       "897595  @nan_diosa @SusanaBeatrzDaz @sebahaesler1 @spl...   es   \n",
       "897596  @AngelesMayer @Camac_Rejas @patricia170919 @LM...   es   \n",
       "897597  @jacquelin_93 @ThEcualizere @kitty_sanrio1 @Si...   es   \n",
       "897598  #GHLaGranFinal #matiasal3002 ,palpitando la gr...   es   \n",
       "\n",
       "                                              tweet_clean place_full_name  \\\n",
       "0                                                                    None   \n",
       "1                    Que chiste ms malo pero me rio igual            None   \n",
       "2         Habia perro llamado pegento, se callo y se pego            None   \n",
       "3       Siento que cada da que pasa es un da menos par...            None   \n",
       "4       La zorra dr mierda va un paso adelante y yo un...            None   \n",
       "...                                                   ...             ...   \n",
       "897594                                       bello grupo             None   \n",
       "897595                                linda noche besotes            None   \n",
       "897596                       buenas noches amigos besitos            None   \n",
       "897597                        feliz noche corazones besos            None   \n",
       "897598   GHLaGranFinal matiasal3002 ,palpitando la gra...            None   \n",
       "\n",
       "       place_name place_type place_country place_country_code  \\\n",
       "0            None       None          None               None   \n",
       "1            None       None          None               None   \n",
       "2            None       None          None               None   \n",
       "3            None       None          None               None   \n",
       "4            None       None          None               None   \n",
       "...           ...        ...           ...                ...   \n",
       "897594       None       None          None               None   \n",
       "897595       None       None          None               None   \n",
       "897596       None       None          None               None   \n",
       "897597       None       None          None               None   \n",
       "897598       None       None          None               None   \n",
       "\n",
       "        coordinates_longitude  coordinates_latitude ner_loc  \n",
       "0                         NaN                   NaN    None  \n",
       "1                         NaN                   NaN    None  \n",
       "2                         NaN                   NaN    None  \n",
       "3                         NaN                   NaN    None  \n",
       "4                         NaN                   NaN    None  \n",
       "...                       ...                   ...     ...  \n",
       "897594                    NaN                   NaN    None  \n",
       "897595                    NaN                   NaN    None  \n",
       "897596                    NaN                   NaN    None  \n",
       "897597                    NaN                   NaN    None  \n",
       "897598                    NaN                   NaN    None  \n",
       "\n",
       "[897599 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in dataframe\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import tqdm\n",
    "\n",
    "df1 = pd.read_feather(\"s3://mt5599/tweets/spanish_tweets_2016_0_processed_wcontent_ner.feather\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c2f91d-3716-475a-9b45-a12b4462aa4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AngelaTorres             2485\n",
       "JA                       1783\n",
       "Argentina                1600\n",
       "Macri                    1399\n",
       "Rosario                  1064\n",
       "                         ... \n",
       "PIBIT                       1\n",
       "Faltan Poco                 1\n",
       "El Jueves                   1\n",
       "TWITTER                     1\n",
       "Jajaja van Besitossss       1\n",
       "Name: ner_loc, Length: 38396, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.ner_loc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be0eb4-1693-403c-badf-7596e40256de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c346bc-cfb1-4134-9107-5274a9d47367",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55568d-c2fb-4d24-bf89-aaf4f29496f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install feather-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d73dd292-07a2-46a4-8629-21585701de2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\"Data Processing Pipeline \"\"\"\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import json\n",
    "import unicodedata\n",
    "import html\n",
    "import tqdm\n",
    "from multiprocessing import Pool # multithreading\n",
    "\n",
    "def clean_tweet_helper(row):\n",
    "    \n",
    "    s = row[1][\"tweet_content\"]\n",
    "    \n",
    "    r = unicodedata.normalize(\"NFC\", s)\n",
    "    r = html.unescape(r)\n",
    "    #r = r.encode(\"ascii\", \"ignore\").decode()\n",
    "    r = r.replace('\\n', \" \")\n",
    "    r = r.replace('@', \" \")\n",
    "    r = r.replace(\"#\", \" \")\n",
    "    r = re.sub('http://\\S+|https://\\S+', '', r)\n",
    "    #r = r.lower()\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    r = (emoji_pattern.sub(r'', r))  # no emoji\n",
    "    r = re.sub('\\s{2,}', ' ', r)\n",
    "    \n",
    "    row[1][\"tweet_clean\"] = r\n",
    "    \n",
    "    return row[1]\n",
    "\n",
    "def clean_tweet(df):\n",
    "    \n",
    "    df['tweet_clean'] = None\n",
    "    \n",
    "    pool = Pool(processes=round(len(df.index)/10000))\n",
    "\n",
    "    result_arr = []\n",
    "    \n",
    "    for result in tqdm.tqdm(pool.imap_unordered(clean_tweet_helper, df.iterrows()),\n",
    "                            total=len(df.index)):\n",
    "        result_arr.append(result)\n",
    "                \n",
    "    df = pd.concat(result_arr, axis=1).transpose().sort_index()\n",
    "                \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236e1dea-eff0-488a-b7c9-eb0cca1a8451",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 851988/851988 [06:42<00:00, 2115.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>lang</th>\n",
       "      <th>like_count</th>\n",
       "      <th>media</th>\n",
       "      <th>mentioned_users</th>\n",
       "      <th>...</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_media_count</th>\n",
       "      <th>user_protected</th>\n",
       "      <th>user_link_url</th>\n",
       "      <th>user_link_tcourl</th>\n",
       "      <th>user_profile_image_url</th>\n",
       "      <th>user_profile_banner_url</th>\n",
       "      <th>user_label</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>722512957247242240</td>\n",
       "      <td>2016-04-19 19:51:27+00:00</td>\n",
       "      <td>https://t.co/CGRUcZWccL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>zxx</td>\n",
       "      <td>0</td>\n",
       "      <td>[Photo(previewUrl='https://pbs.twimg.com/media...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/716693338...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/23586395...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718879627956068352</td>\n",
       "      <td>2016-04-09 19:13:54+00:00</td>\n",
       "      <td>Que chiste más malo pero me rio igual</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/716693338...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/23586395...</td>\n",
       "      <td>None</td>\n",
       "      <td>Que chiste más malo pero me rio igual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>718879522431639552</td>\n",
       "      <td>2016-04-09 19:13:28+00:00</td>\n",
       "      <td>Habia perro llamado pegento, se callo y se pego</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/716693338...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/23586395...</td>\n",
       "      <td>None</td>\n",
       "      <td>Habia perro llamado pegento, se callo y se pego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>718878528020852736</td>\n",
       "      <td>2016-04-09 19:09:31+00:00</td>\n",
       "      <td>Siento que cada día que pasa es un día menos p...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/716693338...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/23586395...</td>\n",
       "      <td>None</td>\n",
       "      <td>Siento que cada día que pasa es un día menos p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>718240922379644928</td>\n",
       "      <td>2016-04-08 00:55:54+00:00</td>\n",
       "      <td>La zorra dr mierda va un paso adelante y yo un...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>571</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/716693338...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/23586395...</td>\n",
       "      <td>None</td>\n",
       "      <td>La zorra dr mierda va un paso adelante y yo un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851983</th>\n",
       "      <td>649401814627041280</td>\n",
       "      <td>2015-10-01 01:53:52+00:00</td>\n",
       "      <td>@rociolupe1 @AngelesMayer @Camac_Rejas @patric...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "      <td>[Photo(previewUrl='https://pbs.twimg.com/media...</td>\n",
       "      <td>[User(username='rociolupe1', id=1607578752, di...</td>\n",
       "      <td>...</td>\n",
       "      <td>649925</td>\n",
       "      <td>73</td>\n",
       "      <td>156742</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/159585027...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/52797215...</td>\n",
       "      <td>None</td>\n",
       "      <td>rociolupe1 AngelesMayer Camac_Rejas patricia1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851984</th>\n",
       "      <td>649378989933490176</td>\n",
       "      <td>2015-10-01 00:23:10+00:00</td>\n",
       "      <td>@nan_diosa @SusanaBeatrzDaz @sebahaesler1 @spl...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>[User(username='nan_diosa', id=190007755, disp...</td>\n",
       "      <td>...</td>\n",
       "      <td>649925</td>\n",
       "      <td>73</td>\n",
       "      <td>156742</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/159585027...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/52797215...</td>\n",
       "      <td>None</td>\n",
       "      <td>nan_diosa SusanaBeatrzDaz sebahaesler1 splale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851985</th>\n",
       "      <td>649378714539716608</td>\n",
       "      <td>2015-10-01 00:22:05+00:00</td>\n",
       "      <td>@AngelesMayer @Camac_Rejas @patricia170919 @LM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>[User(username='AngelesMayer', id=449939512, d...</td>\n",
       "      <td>...</td>\n",
       "      <td>649925</td>\n",
       "      <td>73</td>\n",
       "      <td>156742</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/159585027...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/52797215...</td>\n",
       "      <td>None</td>\n",
       "      <td>AngelesMayer Camac_Rejas patricia170919 LMHH ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851986</th>\n",
       "      <td>649378118281625600</td>\n",
       "      <td>2015-10-01 00:19:42+00:00</td>\n",
       "      <td>@jacquelin_93 @ThEcualizere @kitty_sanrio1 @Si...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[User(username='jacquelin_93', id=287835961, d...</td>\n",
       "      <td>...</td>\n",
       "      <td>649925</td>\n",
       "      <td>73</td>\n",
       "      <td>156742</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/159585027...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/52797215...</td>\n",
       "      <td>None</td>\n",
       "      <td>jacquelin_93 ThEcualizere kitty_sanrio1 Silau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851987</th>\n",
       "      <td>649374394276573184</td>\n",
       "      <td>2015-10-01 00:04:55+00:00</td>\n",
       "      <td>#GHLaGranFinal #matiasal3002 ,palpitando la gr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>['GHLaGranFinal', 'matiasal3002']</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>649925</td>\n",
       "      <td>73</td>\n",
       "      <td>156742</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/159585027...</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/52797215...</td>\n",
       "      <td>None</td>\n",
       "      <td>GHLaGranFinal matiasal3002 ,palpitando la gra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>851988 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                  DateTime  \\\n",
       "0       722512957247242240 2016-04-19 19:51:27+00:00   \n",
       "1       718879627956068352 2016-04-09 19:13:54+00:00   \n",
       "2       718879522431639552 2016-04-09 19:13:28+00:00   \n",
       "3       718878528020852736 2016-04-09 19:09:31+00:00   \n",
       "4       718240922379644928 2016-04-08 00:55:54+00:00   \n",
       "...                    ...                       ...   \n",
       "851983  649401814627041280 2015-10-01 01:53:52+00:00   \n",
       "851984  649378989933490176 2015-10-01 00:23:10+00:00   \n",
       "851985  649378714539716608 2015-10-01 00:22:05+00:00   \n",
       "851986  649378118281625600 2015-10-01 00:19:42+00:00   \n",
       "851987  649374394276573184 2015-10-01 00:04:55+00:00   \n",
       "\n",
       "                                            tweet_content cashtags  \\\n",
       "0                                 https://t.co/CGRUcZWccL     None   \n",
       "1                   Que chiste más malo pero me rio igual     None   \n",
       "2         Habia perro llamado pegento, se callo y se pego     None   \n",
       "3       Siento que cada día que pasa es un día menos p...     None   \n",
       "4       La zorra dr mierda va un paso adelante y yo un...     None   \n",
       "...                                                   ...      ...   \n",
       "851983  @rociolupe1 @AngelesMayer @Camac_Rejas @patric...     None   \n",
       "851984  @nan_diosa @SusanaBeatrzDaz @sebahaesler1 @spl...     None   \n",
       "851985  @AngelesMayer @Camac_Rejas @patricia170919 @LM...     None   \n",
       "851986  @jacquelin_93 @ThEcualizere @kitty_sanrio1 @Si...     None   \n",
       "851987  #GHLaGranFinal #matiasal3002 ,palpitando la gr...     None   \n",
       "\n",
       "       coordinates                           hashtags lang like_count  \\\n",
       "0             None                               None  zxx          0   \n",
       "1             None                               None   es          0   \n",
       "2             None                               None   es          0   \n",
       "3             None                               None   es          1   \n",
       "4             None                               None   es          1   \n",
       "...            ...                                ...  ...        ...   \n",
       "851983        None                               None   it          2   \n",
       "851984        None                               None   es          2   \n",
       "851985        None                               None   es          2   \n",
       "851986        None                               None   es          0   \n",
       "851987        None  ['GHLaGranFinal', 'matiasal3002']   es          0   \n",
       "\n",
       "                                                    media  \\\n",
       "0       [Photo(previewUrl='https://pbs.twimg.com/media...   \n",
       "1                                                    None   \n",
       "2                                                    None   \n",
       "3                                                    None   \n",
       "4                                                    None   \n",
       "...                                                   ...   \n",
       "851983  [Photo(previewUrl='https://pbs.twimg.com/media...   \n",
       "851984                                               None   \n",
       "851985                                               None   \n",
       "851986                                               None   \n",
       "851987                                               None   \n",
       "\n",
       "                                          mentioned_users  ...  \\\n",
       "0                                                    None  ...   \n",
       "1                                                    None  ...   \n",
       "2                                                    None  ...   \n",
       "3                                                    None  ...   \n",
       "4                                                    None  ...   \n",
       "...                                                   ...  ...   \n",
       "851983  [User(username='rociolupe1', id=1607578752, di...  ...   \n",
       "851984  [User(username='nan_diosa', id=190007755, disp...  ...   \n",
       "851985  [User(username='AngelesMayer', id=449939512, d...  ...   \n",
       "851986  [User(username='jacquelin_93', id=287835961, d...  ...   \n",
       "851987                                               None  ...   \n",
       "\n",
       "       user_favourites_count user_listed_count user_media_count  \\\n",
       "0                        571                 0              214   \n",
       "1                        571                 0              214   \n",
       "2                        571                 0              214   \n",
       "3                        571                 0              214   \n",
       "4                        571                 0              214   \n",
       "...                      ...               ...              ...   \n",
       "851983                649925                73           156742   \n",
       "851984                649925                73           156742   \n",
       "851985                649925                73           156742   \n",
       "851986                649925                73           156742   \n",
       "851987                649925                73           156742   \n",
       "\n",
       "       user_protected user_link_url user_link_tcourl  \\\n",
       "0               False          None             None   \n",
       "1               False          None             None   \n",
       "2               False          None             None   \n",
       "3               False          None             None   \n",
       "4               False          None             None   \n",
       "...               ...           ...              ...   \n",
       "851983          False          None             None   \n",
       "851984          False          None             None   \n",
       "851985          False          None             None   \n",
       "851986          False          None             None   \n",
       "851987          False          None             None   \n",
       "\n",
       "                                   user_profile_image_url  \\\n",
       "0       https://pbs.twimg.com/profile_images/716693338...   \n",
       "1       https://pbs.twimg.com/profile_images/716693338...   \n",
       "2       https://pbs.twimg.com/profile_images/716693338...   \n",
       "3       https://pbs.twimg.com/profile_images/716693338...   \n",
       "4       https://pbs.twimg.com/profile_images/716693338...   \n",
       "...                                                   ...   \n",
       "851983  https://pbs.twimg.com/profile_images/159585027...   \n",
       "851984  https://pbs.twimg.com/profile_images/159585027...   \n",
       "851985  https://pbs.twimg.com/profile_images/159585027...   \n",
       "851986  https://pbs.twimg.com/profile_images/159585027...   \n",
       "851987  https://pbs.twimg.com/profile_images/159585027...   \n",
       "\n",
       "                                  user_profile_banner_url user_label  \\\n",
       "0       https://pbs.twimg.com/profile_banners/23586395...       None   \n",
       "1       https://pbs.twimg.com/profile_banners/23586395...       None   \n",
       "2       https://pbs.twimg.com/profile_banners/23586395...       None   \n",
       "3       https://pbs.twimg.com/profile_banners/23586395...       None   \n",
       "4       https://pbs.twimg.com/profile_banners/23586395...       None   \n",
       "...                                                   ...        ...   \n",
       "851983  https://pbs.twimg.com/profile_banners/52797215...       None   \n",
       "851984  https://pbs.twimg.com/profile_banners/52797215...       None   \n",
       "851985  https://pbs.twimg.com/profile_banners/52797215...       None   \n",
       "851986  https://pbs.twimg.com/profile_banners/52797215...       None   \n",
       "851987  https://pbs.twimg.com/profile_banners/52797215...       None   \n",
       "\n",
       "                                              tweet_clean  \n",
       "0                                                          \n",
       "1                   Que chiste más malo pero me rio igual  \n",
       "2         Habia perro llamado pegento, se callo y se pego  \n",
       "3       Siento que cada día que pasa es un día menos p...  \n",
       "4       La zorra dr mierda va un paso adelante y yo un...  \n",
       "...                                                   ...  \n",
       "851983   rociolupe1 AngelesMayer Camac_Rejas patricia1...  \n",
       "851984   nan_diosa SusanaBeatrzDaz sebahaesler1 splale...  \n",
       "851985   AngelesMayer Camac_Rejas patricia170919 LMHH ...  \n",
       "851986   jacquelin_93 ThEcualizere kitty_sanrio1 Silau...  \n",
       "851987   GHLaGranFinal matiasal3002 ,palpitando la gra...  \n",
       "\n",
       "[851988 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = clean_tweet(df1)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a5d2a3f-c70c-4e67-b83e-72c7b2688901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool # multithreading\n",
    "\n",
    "# Second: Initialise the NLP in Spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "        \n",
    "def ner_helper(row):\n",
    "    sptspacy = row[1][\"tweet_clean\"]\n",
    "    doc_sp = nlp(sptspacy)\n",
    "    \n",
    "    spttext = pd.DataFrame([])\n",
    "    sptlabel = pd.DataFrame([])\n",
    "    spttweet = pd.DataFrame([])\n",
    "\n",
    "    for ent in doc_sp.ents:\n",
    "\n",
    "        spttext = spttext.append(pd.DataFrame({'textloc': ent.text}, index = [0]), ignore_index = True)\n",
    "        sptlabel = sptlabel.append(pd.DataFrame({'label': ent.label_}, index = [0]), ignore_index = True)\n",
    "        spttweet = spttweet.append(pd.DataFrame({'TweetNumber': row[1][\"TweetNumber\"]}, index = [0]), ignore_index = True)\n",
    "\n",
    "    # Third: Combining the Spacy Spanish Findings\n",
    "    frames_spacy_sp = [spttweet, spttext, sptlabel]\n",
    "    finalent_spacy_sp = pd.concat(frames_spacy_sp, axis = 1)\n",
    "    \n",
    "    # Fourth: Keep only the GPE parts\n",
    "    if len(finalent_spacy_sp.index) > 0:\n",
    "        gpedf_sp = finalent_spacy_sp[finalent_spacy_sp['label'] == \"LOC\"]\n",
    "\n",
    "        # Fifth: Merge the GPE on the Main Data Frame\n",
    "        sptlocations = pd.merge(row[1].to_frame().transpose(), gpedf_sp, on = \"TweetNumber\", how = \"left\")\n",
    "        \n",
    "    else:\n",
    "        sptlocations = row[1].to_frame().transpose()\n",
    "        sptlocations[\"textloc\"] = None\n",
    "        sptlocations[\"label\"] = None\n",
    "        sptlocations[\"TweetNumber\"] = row[1][\"TweetNumber\"]\n",
    "\n",
    "    return sptlocations\n",
    "\n",
    "\n",
    "\n",
    "# extracting place components\n",
    "def ner(df):\n",
    "    \n",
    "    df = df[df.lang == \"es\"]\n",
    "\n",
    "    pool = Pool(processes=round(len(df.index)/10000))\n",
    "\n",
    "    result_arr = []\n",
    "    \n",
    "    for result in tqdm.tqdm(pool.imap_unordered(ner_helper, df.iterrows()),\n",
    "                            total=len(df.index)):\n",
    "        result_arr.append(result)\n",
    "                \n",
    "    df = pd.concat(result_arr, axis=0).sort_index()\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c9a0dd4-eecd-4023-8e7c-7546948329c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import tqdm\n",
    "from multiprocessing import Pool # multithreading\n",
    "import tqdm\n",
    "from time import process_time\n",
    "import feather\n",
    "  \n",
    "\n",
    "\n",
    "# write function to remove unnecessary columns\n",
    "def keep_columns(df, # dataframe to be cleaned\n",
    "                 columns): # list of columns to keep\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "#write function to keep only tweets with location data\n",
    "def has_loc(df):\n",
    "    df = df[df.coordinates != \"None\"]\n",
    "    df = df[df.place != \"None\"]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# helper function to extract place and coordinates\n",
    "def safe_json_loads(string):\n",
    "    try:\n",
    "        string = json.loads(string)\n",
    "    except:\n",
    "        string = None\n",
    "    return(string)\n",
    "\n",
    "\n",
    "\n",
    "def extract_place_helper(row):\n",
    "    if row[1][\"place\"] != None:\n",
    "        try:\n",
    "            split_by = \"Place\\(fullName='|', name='|', type='|', country='|', countryCode='|'\\)\"\n",
    "            temp = re.split(split_by, row[1][\"place\"])\n",
    "\n",
    "            row[1]['place_full_name'] = float(temp[1])\n",
    "            row[1]['place_name'] = float(temp[2])\n",
    "            row[1]['place_type'] = float(temp[3])\n",
    "            row[1]['place_country'] = float(temp[4])\n",
    "            row[1]['place_country_code'] = float(temp[5])\n",
    "        except:\n",
    "            row[1]['place_full_name'] = None\n",
    "            row[1]['place_name'] = None\n",
    "            row[1]['place_type'] = None\n",
    "            row[1]['place_country'] = None\n",
    "            row[1]['place_country_code'] = None\n",
    "            \n",
    "    return row[1]\n",
    "\n",
    "\n",
    "# extracting place components\n",
    "def extract_place(df):\n",
    "    \n",
    "    df_coord = df\n",
    "    \n",
    "    df_coord['place_full_name'] = None\n",
    "    df_coord['place_name'] = None\n",
    "    df_coord['place_type'] = None\n",
    "    df_coord['place_country'] = None\n",
    "    df_coord['place_country_code'] = None\n",
    "\n",
    "    \n",
    "    pool = Pool(processes=round(len(df_coord.index)/10000))\n",
    "\n",
    "    result_arr = []\n",
    "    \n",
    "    for result in tqdm.tqdm(pool.imap_unordered(extract_place_helper, df_coord.iterrows()),\n",
    "                            total=len(df_coord.index)):\n",
    "        result_arr.append(result)\n",
    "                \n",
    "    df_coord = pd.concat(result_arr, axis=1).transpose().sort_index()\n",
    "                \n",
    "    return df_coord\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_coordinates_helper(row):\n",
    "    if row[1][\"coordinates\"] != None:\n",
    "        try:\n",
    "            split_by = \"Coordinates\\(longitude=|, latitude=|\\)\"\n",
    "            temp = re.split(split_by, row[1][\"coordinates\"])\n",
    "\n",
    "            row[1]['coordinates_longitude'] = float(temp[1])\n",
    "            row[1]['coordinates_latitude'] = float(temp[2])\n",
    "\n",
    "        except:\n",
    "            row[1]['coordinates_longitude'] = None\n",
    "            row[1]['coordinates_latitude'] = None\n",
    "\n",
    "    return row[1]\n",
    "\n",
    "\n",
    "# extracting place components\n",
    "def extract_coordinates(df):\n",
    "    \n",
    "    df_coord = df\n",
    "    \n",
    "    df_coord['coordinates_longitude'] = None\n",
    "    df_coord['coordinates_latitude'] = None\n",
    "    \n",
    "    \n",
    "    pool = Pool(processes=round(len(df_coord.index)/10000))\n",
    "\n",
    "    result_arr = []\n",
    "    \n",
    "    for result in tqdm.tqdm(pool.imap_unordered(extract_coordinates_helper, df_coord.iterrows()),\n",
    "                            total=len(df_coord.index)):\n",
    "        result_arr.append(result)\n",
    "                \n",
    "    df_coord = pd.concat(result_arr, axis=1).transpose().sort_index()\n",
    "                \n",
    "    return df_coord\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22b229ce-19fc-40f9-b795-10b9fef3791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "#def clean_df(filepath):\n",
    "def clean_df(df):\n",
    "    \n",
    "    # reading in data\n",
    "    #print(\"reading in \", filepath)\n",
    "    #print()\n",
    "    #df = pd.read_json(filepath)\n",
    "    \n",
    "\n",
    "    # removing unnecessary columns\n",
    "    print(\"removing unnecessary columns\")\n",
    "    print()\n",
    "    df = keep_columns(df, [\"id\", \"DateTime\", \"coordinates\",\n",
    "                           \"place\", \"username\", \"user_id\", \n",
    "                           \"user_location\", \"tweet_content\", \"lang\"])\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"TweetNumber\"}, inplace=True)\n",
    "\n",
    "    \n",
    "    # cleaning tweet content\n",
    "    print(\"cleaning content of tweets - removing emojis and other symbols\")\n",
    "    df = clean_tweet(df)\n",
    "    print()\n",
    "      \n",
    "    # extracting mentioned locations from tweets\n",
    "    df = ner(df)\n",
    "    print()\n",
    "    \n",
    "    # removing unnecessary column\n",
    "    df.drop(\"TweetNumber\", axis=1)\n",
    "    \n",
    "    \n",
    "    # filtering out tweets that have no location data\n",
    "    print(\"filtering out tweets that have no location data\")\n",
    "    print()\n",
    "    df = has_loc(df)\n",
    "\n",
    "    # extracting components of place\n",
    "    print(\"extracting components of place\")\n",
    "    df = extract_place(df)\n",
    "    print()\n",
    "\n",
    "    # extracting components of coordinates\n",
    "    print(\"extracting components of coordinates\")\n",
    "    df = extract_coordinates(df)\n",
    "    print()\n",
    "    \n",
    "\n",
    "    \n",
    "    #new_filepath = filepath.replace(\".json\", \"_processed_wcontent.feather\")\n",
    "    #df.to_feather(new_filepath)\n",
    "\n",
    "    #return df.shape[0]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a539f7-ef1a-40c2-a296-4586fde940e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing unnecessary columns\n",
      "\n",
      "cleaning content of tweets - removing emojis and other symbols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 232/1000 [00:00<00:00, 2259.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 2250.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▋   | 664/1000 [00:00<00:00, 2189.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2345.78it/s][A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df11 = df1[0:1000]\n",
    "\n",
    "cleaned_df = clean_df(df11)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42cf718-c0c9-4e75-b993-86d3f378b0a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in  s3://mt5599/tweets/spanish_tweets_2016_0.json\n",
      "\n",
      "removing unnecessary columns\n",
      "\n",
      "cleaning content of tweets - removing emojis and other symbols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 851988/851988 [05:55<00:00, 2396.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/736770 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TweetNumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3361, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 76, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'TweetNumber'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"<ipython-input-6-c274ce36d052>\", line 36, in ner_helper\n    sptlocations[\"TweetNumber\"] = row[1][\"TweetNumber\"]\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\", line 942, in __getitem__\n    return self._get_value(key)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\", line 1051, in _get_value\n    loc = self.index.get_loc(label)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3363, in get_loc\n    raise KeyError(key) from err\nKeyError: 'TweetNumber'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-208e23945868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocess_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt1_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mno_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_tweets\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclean_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://mt5599/tweets/spanish_tweets_2016_0.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mt1_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-10aa5d6e8555>\u001b[0m in \u001b[0;36mclean_df\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# extracting mentioned locations from tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c274ce36d052>\u001b[0m in \u001b[0;36mner\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     for result in tqdm.tqdm(pool.imap_unordered(ner_helper, df.iterrows()),\n\u001b[0;32m---> 52\u001b[0;31m                             total=len(df.index)):\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mresult_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TweetNumber'"
     ]
    }
   ],
   "source": [
    "no_tweets = 0\n",
    "\n",
    "from time import process_time\n",
    "t1_start = process_time()\n",
    "no_tweets = no_tweets + clean_df(\"s3://mt5599/tweets/spanish_tweets_2016_0.json\")\n",
    "t1_stop = process_time()\n",
    "print()\n",
    "print(\"elapsed time: \", t1_stop - t1_start)\n",
    "print()\n",
    "print(\"number of tweets \", no_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b90e6e-b77e-447f-bbd9-7d3b6961470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_feather(\"s3://mt5599/tweets/spanish_tweets_2016_0_processed.feather\")\n",
    "df_cleaned[[\"tweet_content\", \"tweet_clean\", \"textloc\", \"coordinates_latitude\", \"coordinates_longitude\", \"place_country\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48dc23-fe08-4346-bdbc-f1c38c54389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    filepaths = []\n",
    "    for i in range(266, 401):\n",
    "        filepath = \"../../data/spanish_tweets_2016_\" + str(i) + \".json\"\n",
    "        filepaths.append(filepath)\n",
    "\n",
    "    filepaths = [\"../../data/spanish_tweets_2016_0.json\"]\n",
    "        \n",
    "    no_tweets = 0\n",
    "    non_existent_files = []\n",
    "    for filepath in filepaths:\n",
    "        try:\n",
    "            t1_start = process_time()\n",
    "            no_tweets = no_tweets + clean_df(filepath)\n",
    "            t1_stop = process_time()\n",
    "            print()\n",
    "            print(\"elapsed time: \", t1_stop - t1_start)\n",
    "            print()\n",
    "        except:\n",
    "            non_existent_files.append(filepath)\n",
    "            continue\n",
    "            \n",
    "    print(\"the number of geotagged tweets collected: \", no_tweets)\n",
    "    print(\"the files that do not exist: \", non_existent_files)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2b288-2673-4f53-a140-23e06b639b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "gmaps = googlemaps.Client(key='AIzaSyCavjrCe_gyDBb5ThDhXDNC2RKPeiknxGQ')\n",
    "\n",
    "# Geocoding an address\n",
    "geocode_result = gmaps.geocode('1600 Amphitheatre Parkway, Mountain View, CA')\n",
    "\n",
    "# Look up an address with reverse geocoding\n",
    "reverse_geocode_result = gmaps.reverse_geocode((40.714224, -73.961452))\n",
    "\n",
    "# Request directions via public transit\n",
    "now = datetime.now()\n",
    "directions_result = gmaps.directions(\"Sydney Town Hall\",\n",
    "                                     \"Parramatta, NSW\",\n",
    "                                     mode=\"transit\",\n",
    "                                     departure_time=now)\n",
    "\n",
    "# Validate an address with address validation\n",
    "addressvalidation_result =  gmaps.addressvalidation(['1600 Amphitheatre Pk'], \n",
    "                                                    regionCode='US',\n",
    "                                                    locality='Mountain View', \n",
    "                                                    enableUspsCass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b0615-44c0-405c-ae0d-727a4a699133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make the empty dataframes for lat and long\n",
    "sptlat = pd.DataFrame([])\n",
    "sptlong = pd.DataFrame([])\n",
    "spttweet_2 = pd.DataFrame([])\n",
    "\n",
    "# Create  the lat and long variables to add to the data\n",
    "\n",
    "lensptw = len(sptlocations[\"text\"])\n",
    "\n",
    "# Initialize the loop for the API\n",
    "for i in np.arange(0, lensptw):\n",
    "    sptloc = sptlocations[\"textloc\"][i]\n",
    "    geo_code_result_sp = gmaps.geocode(sptloc)\n",
    "    # If there is no location in the tweet, enter (0,0) for lat and long\n",
    "    elif len(geo_code_result_sp) == 0:\n",
    "        sptlat = sptlat.append(pd.DataFrame({\"Lat\": 0}, index = [0]), ignore_index = True)\n",
    "        sptlong = sptlat.append(pd.DataFrame({\"Long\": 0}, index = [0]), ignore_index = True)\n",
    "        spttweet_2 = spttweet_2.append(pd.DataFrame({\"TweetNumber\": [i]}, index = [0]), ignore_index=True)\n",
    "    # Else, get the lat and long from the dictionarise and subdictionaries\n",
    "    else:\n",
    "        geo_code_dict_sp = geo_code_result_sp[0]\n",
    "        geo_code_geometry_dict_sp = geo_code_dict_sp.get(\"geometry\")\n",
    "        geo_location_sp = geo_code_geometry_dict_sp.get(\"location\")\n",
    "        sptlat = sptlat.append(pd.DataGrame({\"Lat\": geo_location_sp.get(\"lat\")}, index = [0]), ignore_index = True)\n",
    "        sptlong = sptlat.append(pd.DataGrame({\"Long\": geo_location_sp.get(\"lng\")}, index = [0]), ignore_index = True)\n",
    "        spttweet_2 = spttweet_2.append(pd.DataFrame({\"TweetNumber\": [i]}, index = [0]), ignore_index = True)\n",
    "        \n",
    "\n",
    "# Concatenate dataframes\n",
    "# https://pandas.pydata.org/docs/user_guide/merging.html\n",
    "framesloc_sp = [splat, splong]\n",
    "finalloc_sp = pd.concat(framesloc_sp, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:712779665605:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
