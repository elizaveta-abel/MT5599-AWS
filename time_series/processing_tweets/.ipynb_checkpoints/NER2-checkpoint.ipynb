{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452467cc-4448-4b21-b0e6-8560ed74ca79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in dataframe\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import tqdm\n",
    "\n",
    "df1 = pd.read_json(\"s3://mt5599/tweets/spanish_tweets_2016_0.json\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34be0eb4-1693-403c-badf-7596e40256de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (59.3.0)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.42.1)\n",
      "Collecting typing-extensions<4.2.0,>=3.7.4\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (20.1)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (814 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.10\n",
      "  Using cached spacy_legacy-3.0.11-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.21.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.1.2)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (1.14.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy) (5.1.0)\n",
      "Installing collected packages: wasabi, cymem, typing-extensions, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, blis, pydantic, preshed, catalogue, srsly, click, typer, confection, thinc, pathy, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: Click 7.0\n",
      "    Uninstalling Click-7.0:\n",
      "      Successfully uninstalled Click-7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.4.1 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.24 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-0.7.9 catalogue-2.0.8 click-8.1.3 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.2 smart-open-6.3.0 spacy-3.4.4 spacy-legacy-3.0.11 spacy-loggers-1.0.4 srsly-2.4.5 thinc-8.1.6 typer-0.7.0 typing-extensions-4.1.1 wasabi-0.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c346bc-cfb1-4134-9107-5274a9d47367",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (22.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (59.3.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (0.34.2)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 59.3.0\n",
      "    Uninstalling setuptools-59.3.0:\n",
      "      Successfully uninstalled setuptools-59.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-65.6.3 wheel-0.38.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (3.4.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.1.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (20.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.21.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (8.1.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.11.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.13)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy) (5.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting es-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.4.0/es_core_news_sm-3.4.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from es-core-news-sm==3.4.0) (3.4.4)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (8.1.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (4.42.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (6.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.11)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (20.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.21.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (65.6.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.14.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (5.1.0)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac55568d-c2fb-4d24-bf89-aaf4f29496f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting feather-format\n",
      "  Using cached feather_format-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: pyarrow>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from feather-format) (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow>=0.4.0->feather-format) (1.21.6)\n",
      "Installing collected packages: feather-format\n",
      "Successfully installed feather-format-0.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install feather-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73dd292-07a2-46a4-8629-21585701de2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\"Data Processing Pipeline \"\"\"\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import json\n",
    "import unicodedata\n",
    "import html\n",
    "import tqdm\n",
    "\n",
    "def clean_tweet_helper(row):\n",
    "    \n",
    "    s = row[1][\"tweet_content\"]\n",
    "    \n",
    "    r = unicodedata.normalize(\"NFC\", s)\n",
    "    r = html.unescape(r)\n",
    "    #r = r.encode(\"ascii\", \"ignore\").decode()\n",
    "    r = r.replace('\\n', \" \")\n",
    "    r = r.replace('@', \" \")\n",
    "    r = r.replace(\"#\", \" \")\n",
    "    r = re.sub('http://\\S+|https://\\S+', '', r)\n",
    "    #r = r.lower()\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    r = (emoji_pattern.sub(r'', r))  # no emoji\n",
    "    r = re.sub('\\s{2,}', ' ', r)\n",
    "    \n",
    "    row[1][\"tweet_clean\"] = r\n",
    "    \n",
    "    return row[1]\n",
    "\n",
    "def clean_tweet(df):\n",
    "    \n",
    "    df['tweet_clean'] = None\n",
    "    \n",
    "    pool = Pool(processes=round(len(df.index)/1000))\n",
    "\n",
    "    result_arr = []\n",
    "    \n",
    "    for result in tqdm.tqdm(pool.imap_unordered(clean_tweet_helper, df.iterrows()),\n",
    "                            total=len(df.index)):\n",
    "        result_arr.append(result)\n",
    "                \n",
    "    df = pd.concat(result_arr, axis=1).transpose().sort_index()\n",
    "                \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e1dea-eff0-488a-b7c9-eb0cca1a8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5d2a3f-c70c-4e67-b83e-72c7b2688901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool # multithreading\n",
    "\n",
    "# Second: Initialise the NLP in Spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "        \n",
    "def ner_helper(row):\n",
    "    sptspacy = row[1][\"tweet_content\"]\n",
    "    doc_sp = nlp(sptspacy)\n",
    "    \n",
    "    spttext = pd.DataFrame([])\n",
    "    sptlabel = pd.DataFrame([])\n",
    "    spttweet = pd.DataFrame([])\n",
    "\n",
    "    for ent in doc_sp.ents:\n",
    "\n",
    "        spttext = spttext.append(pd.DataFrame({'textloc': ent.text}, index = [0]), ignore_index = True)\n",
    "        sptlabel = sptlabel.append(pd.DataFrame({'label': ent.label_}, index = [0]), ignore_index = True)\n",
    "        spttweet = spttweet.append(pd.DataFrame({'TweetNumber': row[1][\"TweetNumber\"]}, index = [0]), ignore_index = True)\n",
    "\n",
    "    # Third: Combining the Spacy Spanish Findings\n",
    "    frames_spacy_sp = [spttweet, spttext, sptlabel]\n",
    "    finalent_spacy_sp = pd.concat(frames_spacy_sp, axis = 1)\n",
    "    \n",
    "    # Fourth: Keep only the GPE parts\n",
    "    if len(finalent_spacy_sp.index) > 0:\n",
    "        gpedf_sp = finalent_spacy_sp[finalent_spacy_sp['label'] == \"LOC\"]\n",
    "\n",
    "        # Fifth: Merge the GPE on the Main Data Frame\n",
    "        sptlocations = pd.merge(row[1].to_frame().transpose(), gpedf_sp, on = \"TweetNumber\", how = \"left\")\n",
    "        \n",
    "    else:\n",
    "        sptlocations = row[1].to_frame().transpose()\n",
    "        sptlocations[\"textloc\"] = None\n",
    "        sptlocations[\"label\"] = None\n",
    "        sptlocations[\"TweetNumber\"] = row[1][\"TweetNumber\"]\n",
    "\n",
    "    return sptlocations\n",
    "\n",
    "\n",
    "\n",
    "# extracting place components\n",
    "def ner(df):\n",
    "    \n",
    "    df = df[df.lang == \"es\"]\n",
    "\n",
    "    pool = Pool(processes=round(len(df.index)/1000))\n",
    "\n",
    "    result_arr = []\n",
    "    \n",
    "    for result in tqdm.tqdm(pool.imap_unordered(ner_helper, df.iterrows()),\n",
    "                            total=len(df.index)):\n",
    "        result_arr.append(result)\n",
    "                \n",
    "    df = pd.concat(result_arr, axis=0).sort_index()\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9a0dd4-eecd-4023-8e7c-7546948329c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import tqdm\n",
    "from multiprocessing import Pool # multithreading\n",
    "import tqdm\n",
    "from time import process_time\n",
    "import feather\n",
    "  \n",
    "\n",
    "\n",
    "# write function to remove unnecessary columns\n",
    "def keep_columns(df, # dataframe to be cleaned\n",
    "                 columns): # list of columns to keep\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "#write function to keep only tweets with location data\n",
    "def has_loc(df):\n",
    "    df = df[df.coordinates != \"None\"]\n",
    "    df = df[df.place != \"None\"]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# helper function to extract place and coordinates\n",
    "def safe_json_loads(string):\n",
    "    try:\n",
    "        string = json.loads(string)\n",
    "    except:\n",
    "        string = None\n",
    "    return(string)\n",
    "\n",
    "\n",
    "\n",
    "def extract_place_helper(row):\n",
    "    if row[1][\"place\"] != \"None\":\n",
    "        try:\n",
    "            split_by = \"Place\\(fullName='|', name='|', type='|', country='|', countryCode='|'\\)\"\n",
    "            temp = re.split(split_by, row[1][\"place\"])\n",
    "\n",
    "            row[1]['place_full_name'] = temp[1]\n",
    "            row[1]['place_name'] = temp[2]\n",
    "            row[1]['place_type'] = temp[3]\n",
    "            row[1]['place_country'] = temp[4]\n",
    "            row[1]['place_country_code'] = temp[5]\n",
    "        except:\n",
    "            row[1]['place_full_name'] = None\n",
    "            row[1]['place_name'] = None\n",
    "            row[1]['place_type'] = None\n",
    "            row[1]['place_country'] = None\n",
    "            row[1]['place_country_code'] = None\n",
    "            \n",
    "    return row[1]\n",
    "\n",
    "\n",
    "# extracting place components\n",
    "def extract_place(df):\n",
    "    \n",
    "    df_coord = df\n",
    "    \n",
    "    df_coord['place_full_name'] = \"None\"\n",
    "    df_coord['place_name'] = \"None\"\n",
    "    df_coord['place_type'] = \"None\"\n",
    "    df_coord['place_country'] = \"None\"\n",
    "    df_coord['place_country_code'] = \"None\"\n",
    "\n",
    "    \n",
    "    pool = Pool(processes=round(len(df_coord.index)/1000))\n",
    "\n",
    "    result_arr = []\n",
    "    \n",
    "    for result in tqdm.tqdm(pool.imap_unordered(extract_place_helper, df_coord.iterrows()),\n",
    "                            total=len(df_coord.index)):\n",
    "        result_arr.append(result)\n",
    "                \n",
    "    df_coord = pd.concat(result_arr, axis=1).transpose().sort_index()\n",
    "                \n",
    "    return df_coord\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_coordinates_helper(row):\n",
    "    if row[1][\"coordinates\"] != \"None\":\n",
    "        try:\n",
    "            split_by = \"Coordinates\\(longitude=|, latitude=|\\)\"\n",
    "            temp = re.split(split_by, row[1][\"coordinates\"])\n",
    "\n",
    "            row[1]['coordinates_longitude'] = temp[1]\n",
    "            row[1]['coordinates_latitude'] = temp[2]\n",
    "\n",
    "        except:\n",
    "            row[1]['coordinates_longitude'] = None\n",
    "            row[1]['coordinates_latitude'] = None\n",
    "\n",
    "    return row[1]\n",
    "\n",
    "\n",
    "# extracting place components\n",
    "def extract_coordinates(df):\n",
    "    \n",
    "    df_coord = df\n",
    "    \n",
    "    df_coord['coordinates_longitude'] = \"None\"\n",
    "    df_coord['coordinates_latitude'] = \"None\"\n",
    "    \n",
    "    \n",
    "    pool = Pool(processes=round(len(df_coord.index)/1000))\n",
    "\n",
    "    result_arr = []\n",
    "    \n",
    "    for result in tqdm.tqdm(pool.imap_unordered(extract_coordinates_helper, df_coord.iterrows()),\n",
    "                            total=len(df_coord.index)):\n",
    "        result_arr.append(result)\n",
    "                \n",
    "    df_coord = pd.concat(result_arr, axis=1).transpose().sort_index()\n",
    "                \n",
    "    return df_coord\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b229ce-19fc-40f9-b795-10b9fef3791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(filepath):\n",
    "    \n",
    "    # reading in data\n",
    "    print(\"reading in \", filepath)\n",
    "    print()\n",
    "    df = pd.read_json(filepath)\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"TweetNumber\"}, inplace=True)\n",
    "\n",
    "    # removing unnecessary columns\n",
    "    print(\"removing unnecessary columns\")\n",
    "    print()\n",
    "    df = keep_columns(df, [\"id\", \"DateTime\", \"coordinates\",\n",
    "                           \"place\", \"username\", \"user_id\", \n",
    "                           \"user_location\", \"tweet_content\"])\n",
    "\n",
    "    # filtering out tweets that have no location data\n",
    "    #print(\"filtering out tweets that have no location data\")\n",
    "    #print()\n",
    "    #df = has_loc(df)\n",
    "\n",
    "    # extracting components of place\n",
    "    #print(\"extracting components of place\")\n",
    "    #df = extract_place(df)\n",
    "    #print()\n",
    "\n",
    "    # extracting components of coordinates\n",
    "    #print(\"extracting components of coordinates\")\n",
    "    #df = extract_coordinates(df)\n",
    "    #print()\n",
    "    \n",
    "    # cleaning tweet content\n",
    "    print(\"cleaning content of tweets - removing emojis and other symbols\")\n",
    "    df = clean_tweet(df)\n",
    "    print()\n",
    "    \n",
    "    # extracting mentioned locations from tweets\n",
    "    df = ner(df)\n",
    "    print()\n",
    "    \n",
    "    # removing unnecessary column\n",
    "    df.drop(\"TweetNumber\")\n",
    "    \n",
    "    #new_filepath = filepath.replace(\".json\", \"_processed.feather\")\n",
    "    #df.to_feather(new_filepath)\n",
    "\n",
    "    #return df.shape[0]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a539f7-ef1a-40c2-a296-4586fde940e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in  s3://mt5599/tweets/spanish_tweets_2016_0.json\n",
      "\n",
      "removing unnecessary columns\n",
      "\n",
      "cleaning content of tweets - removing emojis and other symbols\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = clean_df(\"s3://mt5599/tweets/spanish_tweets_2016_0.json\")\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48dc23-fe08-4346-bdbc-f1c38c54389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    filepaths = []\n",
    "    for i in range(266, 401):\n",
    "        filepath = \"../../data/spanish_tweets_2016_\" + str(i) + \".json\"\n",
    "        filepaths.append(filepath)\n",
    "\n",
    "    filepaths = [\"../../data/spanish_tweets_2016_0.json\"]\n",
    "        \n",
    "    no_tweets = 0\n",
    "    non_existent_files = []\n",
    "    for filepath in filepaths:\n",
    "        try:\n",
    "            t1_start = process_time()\n",
    "            no_tweets = no_tweets + clean_df(filepath)\n",
    "            t1_stop = process_time()\n",
    "            print()\n",
    "            print(\"elapsed time: \", t1_stop - t1_start)\n",
    "            print()\n",
    "        except:\n",
    "            non_existent_files.append(filepath)\n",
    "            continue\n",
    "            \n",
    "    print(\"the number of geotagged tweets collected: \", no_tweets)\n",
    "    print(\"the files that do not exist: \", non_existent_files)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2b288-2673-4f53-a140-23e06b639b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "gmaps = googlemaps.Client(key='AIzaSyCavjrCe_gyDBb5ThDhXDNC2RKPeiknxGQ')\n",
    "\n",
    "# Geocoding an address\n",
    "geocode_result = gmaps.geocode('1600 Amphitheatre Parkway, Mountain View, CA')\n",
    "\n",
    "# Look up an address with reverse geocoding\n",
    "reverse_geocode_result = gmaps.reverse_geocode((40.714224, -73.961452))\n",
    "\n",
    "# Request directions via public transit\n",
    "now = datetime.now()\n",
    "directions_result = gmaps.directions(\"Sydney Town Hall\",\n",
    "                                     \"Parramatta, NSW\",\n",
    "                                     mode=\"transit\",\n",
    "                                     departure_time=now)\n",
    "\n",
    "# Validate an address with address validation\n",
    "addressvalidation_result =  gmaps.addressvalidation(['1600 Amphitheatre Pk'], \n",
    "                                                    regionCode='US',\n",
    "                                                    locality='Mountain View', \n",
    "                                                    enableUspsCass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41101408-ff53-4af1-8f7d-f42916afe1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting googlemaps\n",
      "  Downloading googlemaps-4.7.3.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from googlemaps) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.26.13)\n",
      "Building wheels for collected packages: googlemaps\n",
      "  Building wheel for googlemaps (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googlemaps: filename=googlemaps-4.7.3-py3-none-any.whl size=40342 sha256=6e92e8afd432921edf2df00e47c5f4ac982a272db3b5bb3f577e0a621553cccb\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/29/ed/84090c49f9572ea576ce9384d9ff02f7d4325c985710c53c4e\n",
      "Successfully built googlemaps\n",
      "Installing collected packages: googlemaps\n",
      "Successfully installed googlemaps-4.7.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a86191-23fd-4791-9deb-5b0aa82983d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address_components': [{'long_name': 'Santa Monica',\n",
       "    'short_name': 'Santa Monica',\n",
       "    'types': ['locality', 'political']},\n",
       "   {'long_name': 'Los Angeles County',\n",
       "    'short_name': 'Los Angeles County',\n",
       "    'types': ['administrative_area_level_2', 'political']},\n",
       "   {'long_name': 'California',\n",
       "    'short_name': 'CA',\n",
       "    'types': ['administrative_area_level_1', 'political']},\n",
       "   {'long_name': 'United States',\n",
       "    'short_name': 'US',\n",
       "    'types': ['country', 'political']}],\n",
       "  'formatted_address': 'Santa Monica, CA, USA',\n",
       "  'geometry': {'bounds': {'northeast': {'lat': 34.05056, 'lng': -118.443426},\n",
       "    'southwest': {'lat': 33.993161, 'lng': -118.5180849}},\n",
       "   'location': {'lat': 34.0194543, 'lng': -118.4911912},\n",
       "   'location_type': 'APPROXIMATE',\n",
       "   'viewport': {'northeast': {'lat': 34.05056, 'lng': -118.443426},\n",
       "    'southwest': {'lat': 33.993161, 'lng': -118.5180849}}},\n",
       "  'place_id': 'ChIJGQCRws6kwoARq_Uj_7UKF7Q',\n",
       "  'types': ['locality', 'political']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import googlemaps\n",
    "\n",
    "gmaps = googlemaps.Client(key='AIzaSyCavjrCe_gyDBb5ThDhXDNC2RKPeiknxGQ')\n",
    "\n",
    "geocode_result = gmaps.geocode(\"Santa Monica\")\n",
    "geocode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b0615-44c0-405c-ae0d-727a4a699133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make the empty dataframes for lat and long\n",
    "sptlat = pd.DataFrame([])\n",
    "sptlong = pd.DataFrame([])\n",
    "spttweet_2 = pd.DataFrame([])\n",
    "\n",
    "# Create  the lat and long variables to add to the data\n",
    "\n",
    "lensptw = len(sptlocations[\"text\"])\n",
    "\n",
    "# Initialize the loop for the API\n",
    "for i in np.arange(0, lensptw):\n",
    "    sptloc = sptlocations[\"textloc\"][i]\n",
    "    geo_code_result_sp = gmaps.geocode(sptloc)\n",
    "    # If there is no location in the tweet, enter (0,0) for lat and long\n",
    "    elif len(geo_code_result_sp) == 0:\n",
    "        sptlat = sptlat.append(pd.DataFrame({\"Lat\": 0}, index = [0]), ignore_index = True)\n",
    "        sptlong = sptlat.append(pd.DataFrame({\"Long\": 0}, index = [0]), ignore_index = True)\n",
    "        spttweet_2 = spttweet_2.append(pd.DataFrame({\"TweetNumber\": [i]}, index = [0]), ignore_index=True)\n",
    "    # Else, get the lat and long from the dictionarise and subdictionaries\n",
    "    else:\n",
    "        geo_code_dict_sp = geo_code_result_sp[0]\n",
    "        geo_code_geometry_dict_sp = geo_code_dict_sp.get(\"geometry\")\n",
    "        geo_location_sp = geo_code_geometry_dict_sp.get(\"location\")\n",
    "        sptlat = sptlat.append(pd.DataGrame({\"Lat\": geo_location_sp.get(\"lat\")}, index = [0]), ignore_index = True)\n",
    "        sptlong = sptlat.append(pd.DataGrame({\"Long\": geo_location_sp.get(\"lng\")}, index = [0]), ignore_index = True)\n",
    "        spttweet_2 = spttweet_2.append(pd.DataFrame({\"TweetNumber\": [i]}, index = [0]), ignore_index = True)\n",
    "        \n",
    "\n",
    "# Concatenate dataframes\n",
    "# https://pandas.pydata.org/docs/user_guide/merging.html\n",
    "framesloc_sp = [splat, splong]\n",
    "finalloc_sp = pd.concat(framesloc_sp, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:712779665605:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
